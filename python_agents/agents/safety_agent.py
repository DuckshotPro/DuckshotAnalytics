"""
Safety Agent

This agent is responsible for screening the data fetched from the Snapchat API
and the insights generated by the analysis agent.
"""

import sys
import os
from typing import Dict, Any

# Add parent directory to path for imports
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from agents.base_agent import Agent


class SafetyAgent(Agent):
    """
    Agent responsible for screening data for safety concerns.
    
    This agent:
    1. Screens Snapchat data for PII (Personally Identifiable Information)
    2. Screens insights for inappropriate content
    """
    
    async def run(self, snapchat_data: Dict[str, Any], insights: str) -> bool:
        """
        Screen data for safety concerns
        
        Args:
            snapchat_data: Dictionary containing Snapchat analytics data
            insights: Generated insight text
        
        Returns:
            True if screening passes
        
        Raises:
            ValueError: If safety screening fails
        """
        print("Safety Agent: Screening data")
        
        # 1. Screen Snapchat data for PII
        if self._contains_pii(snapchat_data):
            raise ValueError("Snapchat data contains PII")
        
        # 2. Screen insights for inappropriate content
        if self._contains_inappropriate_content(insights):
            raise ValueError("Insights contain inappropriate content")
        
        print("Safety Agent: Data screening complete")
        
        return True
    
    def _contains_pii(self, data: Dict[str, Any]) -> bool:
        """
        Check if data contains Personally Identifiable Information
        
        Args:
            data: Data to check
        
        Returns:
            True if PII detected, False otherwise
        """
        # TODO: Implement PII detection logic
        # This could include checking for:
        # - Email addresses
        # - Phone numbers
        # - Social security numbers
        # - Physical addresses
        return False
    
    def _contains_inappropriate_content(self, text: str) -> bool:
        """
        Check if text contains inappropriate content
        
        Args:
            text: Text to check
        
        Returns:
            True if inappropriate content detected, False otherwise
        """
        # TODO: Implement inappropriate content detection logic
        # This could include checking for:
        # - Profanity
        # - Hate speech
        # - Violent content
        # - Spam
        return False